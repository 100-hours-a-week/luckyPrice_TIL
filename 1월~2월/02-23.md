## 1단계: 쿠버네티스 클러스터 구축 및 애플리케이션 배포
목표:
쿠버네티스 클러스터를 구축하고, 웹 애플리케이션을 컨테이너 기반으로 배포한 후, 서비스(Service) 설정을 통해 외부에서 접근 가능하도록 구성


✅ 수행 과정
쿠버네티스 클러스터 구축



### 1. AWS EC2 기반의 멀티노드 클러스터 Kubeadm 구축

[멀티 노드 클러스터 구축.](https://velog.io/@luckyprice1103/%EB%A9%80%ED%8B%B0%EB%85%B8%EB%93%9C-Kubernetes-%ED%81%B4%EB%9F%AC%EC%8A%A4%ED%84%B0-%EA%B5%AC%EC%B6%95)

노드 확장을 고려한 구조 설계 및 네트워크 구성

✅ 1. 노드 확장 고려 여부 점검
![](https://velog.velcdn.com/images/luckyprice1103/post/2447f1e7-e142-47b6-a555-a0550cd0ed4b/image.png)


✅ 2. 네트워크 구성 검토 및 최적화
![](https://velog.velcdn.com/images/luckyprice1103/post/fe628311-7b44-429f-93ea-b9310c9965fd/image.png)




### 2. 애플리케이션 컨테이너 배포

개발팀에서 제공한 Nginx 또는 Node.js 기반 컨테이너 이미지 배포
Deployment 생성 및 다중 파드 배포

(1) Deployment 매니페스트 작성
Deployment를 이용해 애플리케이션을 컨테이너 기반으로 배포.

(app-deployment.yaml)

``` yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: my-web-app
  labels:
    app: my-web-app
spec:
  replicas: 3  # 3개의 파드를 생성
  selector:
    matchLabels:
      app: my-web-app
  template:
    metadata:
      labels:
        app: my-web-app
    spec:
      containers:
        - name: my-web-app
          image: nginx:latest  # 개발팀 제공 이미지 사용 가능
          ports:
            - containerPort: 80
          resources:
            requests:
              cpu: "100m"
              memory: "128Mi"
            limits:
              cpu: "500m"
              memory: "512Mi"
```

replicas: 3 → 파드를 3개 배포하여 부하를 분산
image: nginx:latest → 최신 Nginx 이미지를 사용
containerPort: 80 → 웹 서비스 포트 설정
resources → CPU 및 메모리 사용량 설정 (적절한 값으로 조정 가능)

- t3.medium의 기본적인 스펙:
vCPU: 2개
RAM: 4GB (4096Mi)
네트워크 성능: 중간
EBS 대역폭: 5Gbps
두 개의 워커 노드를 사용하므로 총 가용 자원은:
CPU: 2vCPU × 2 = 4vCPU
메모리: 4GB × 2 = 8GB



- 각 파드의 최소 요구량(Requests)
CPU: 100m (0.1 vCPU)
메모리: 128Mi
- 각 파드의 최대 사용 가능량(Limits)
CPU: 500m (0.5 vCPU)
메모리: 512Mi

- 3개의 파드가 최소 요구량만 사용하는 경우
CPU: 100m × 3 = 300m (0.3 vCPU)
메모리: 128Mi × 3 = 384Mi
💡 이 경우, t3.medium 노드 하나(2 vCPU, 4GB)로 충분히 감당 가능
💡 즉, 하나의 노드에서도 충분히 운영 가능하며, 두 개의 노드가 있다면 여유롭게 운영됨

- 3개의 파드가 최대 Limits까지 사용하는 경우
CPU: 500m × 3 = 1500m (1.5 vCPU)
메모리: 512Mi × 3 = 1536Mi
💡 t3.medium 하나의 2 vCPU와 4GB 내에서 운영 가능
💡 노드가 2개이므로 총 4 vCPU / 8GB 메모리로 충분한 여유 공간 확보

(2) Deployment 배포.

``` bash
kubectl apply -f app-deployment.yaml
```
![](https://velog.velcdn.com/images/luckyprice1103/post/193aaf80-280c-4f11-8413-e266b5ce769e/image.png)


kubectl scale 명령어를 사용하여 replicas 개수를 조정


``` bash
kubectl scale deployment my-web-app --replicas=4
```

![](https://velog.velcdn.com/images/luckyprice1103/post/a6b8e6ce-7625-473e-894e-415b6a385255/image.png)
-> 4개로 늘어남.

### 3. 서비스 설정 및 트래픽 관리

로드 밸런싱을 위한 Service (LoadBalancer / Ingress) 설정
외부에서 애플리케이션 접근 테스트 및 네트워크 문제 해결

service-nodeport.yaml
```yaml
apiVersion: v1
kind: Service
metadata:
  name: my-web-service
spec:
  selector:
    app: my-web-app
  type: NodePort  # 외부에서 접근 가능하도록 설정
  ports:
    - protocol: TCP
      port: 80          # 서비스에서 사용할 포트
      targetPort: 80    # 컨테이너 내부 포트
      nodePort: 30080   # 노드에서 접근할 포트 (30000~32767 사이)

```

```bash
kubectl apply -f service-nodeport.yaml
```

![](https://velog.velcdn.com/images/luckyprice1103/post/31b9325f-6967-4fc9-be35-eb7dcd092bab/image.png)


외부 접속 성공...!(보안 그룹에서도 포트 열어주기.)
![](https://velog.velcdn.com/images/luckyprice1103/post/fa638049-8d3a-4d46-8626-07d6e617afb3/image.png)



service-loadbalancer.yaml
```yaml
apiVersion: v1
kind: Service
metadata:
  name: my-web-service
  annotations:
    service.beta.kubernetes.io/aws-load-balancer-type: "nlb"
    service.beta.kubernetes.io/aws-load-balancer-scheme: "internet-facing"
spec:
  selector:
    app: my-web-app
  type: LoadBalancer  # 클라우드 환경에서는 LoadBalancer 자동 생성됨
  ports:
    - protocol: TCP
      port: 80          # 서비스에서 사용할 포트
      targetPort: 80    # 컨테이너 내부 포트


```

```yaml
kubectl apply -f service-loadbalancer.yaml
kubectl get svc

```

![](https://velog.velcdn.com/images/luckyprice1103/post/aa91ba7d-7b1d-4657-bcc5-18d76ec620cb/image.png)

- external-ip가 pending에서 멈춰있음.-> loadbalacner를 못 만드는 상태


💡 AWS LoadBalancer Controller를 사용하려면, EC2 인스턴스에 IAM Role을 부여해야 함.




✅ 1️⃣ 환경 설정 및 준비
✔ 멀티 노드 클러스터 구축 (1 Master, 2 Worker)
✔ EC2 IAM 역할 부여 (LoadBalancer Controller 사용 가능하도록 설정)

AWS 콘솔에서 IAM 역할 생성

IAM → Roles → Create Role 클릭
EC2 선택 → Next
정책 추가 → AdministratorAccess 선택 (테스트용)
역할 이름: K8s-EC2-Role
Create Role 완료
EC2 인스턴스에 IAM Role 할당

AWS 콘솔 → EC2 → 해당 인스턴스 선택
"Actions" → "Security" → "Modify IAM Role" 클릭
IAM Role을 K8s-EC2-Role로 변경
저장 후 적용

✔ AWS Load Balancer Controller 설치 (Helm 사용)

✅ 2️⃣ 문제 발생 & 해결 과정
🚨 문제 1: LoadBalancer 생성되지만 External IP <pending> 상태
❌ 원인: AWS Load Balancer Controller가 올바른 서브넷을 찾지 못함
🔧 해결: Public Subnet을 kubernetes.io/role/elb=1 태그로 설정


```bash
aws ec2 create-tags --resources <SUBNET_ID> --tags Key=kubernetes.io/role/elb,Value=1
```
🚨 문제 2: Target Group이 Worker 노드를 등록하지 않음
❌ 원인: Worker 노드에 providerID가 설정되지 않음
🔧 해결: Worker 노드에 providerID 추가


```bash
kubectl patch node worker01 -p '{"spec":{"providerID":"aws://ap-northeast-2a/i-02655819459c13fc2"}}'
kubectl patch node worker02 -p '{"spec":{"providerID":"aws://ap-northeast-2b/i-0e99432702999f559"}}'
```
🔧 kubelet 재시작 후 확인


```bash
sudo systemctl restart kubelet
kubectl get nodes -o jsonpath='{range .items[*]}{.metadata.name}{" → "}{.spec.providerID}{"\n"}{end}'
```
🚨 문제 3: LoadBalancer는 생성되었지만 접속이 안됨
❌ 원인:

Target Group이 Worker 노드를 unhealthy 상태로 인식

✅ Target Group 상태 확인 & Worker 노드가 healthy인지 체크

```bash
  aws elbv2 describe-load-balancers --query "LoadBalancers[*].{Name:LoadBalancerName,DNS:DNSName,ARN:LoadBalancerArn}" --output json
aws elbv2 describe-target-groups --query "TargetGroups[*].{Name:TargetGroupName,ARN:TargetGroupArn}" --output json
```

  
```bash
aws elbv2 describe-target-health --target-group-arn <TARGET_GROUP_ARN>
aws elbv2 describe-target-health --target-group-arn arn:aws:elasticloadbalancing:ap-northeast-2:509399622222:targetgroup/k8s-default-mywebser-7ea040c771/e96dae729e11a684
  aws elbv2 describe-target-groups --query "TargetGroups[?TargetGroupName=='k8s-default-mywebser-7ea040c771']"
```
✅ LoadBalancer Controller 재시작

```bash
kubectl delete pod -n kube-system -l app.kubernetes.io/name=aws-load-balancer-controller
```
✅ 3️⃣ 최종 확인 & 성공 🎉
✔ kubectl get svc my-web-service 실행 시 External IP 생성됨
✔ LoadBalancer DNS로 접속 가능
✔ Target Group에서 Worker 노드가 healthy 상태

![](https://velog.velcdn.com/images/luckyprice1103/post/906768b7-33cd-47f5-b0f5-2069c187f916/image.png)

  
  ### 4. Ingress 설정 및 외부 접근 구성
  
  ✅ 목표:

AWS **NLB(Network Load Balancer)**를 사용하여 Ingress Controller와 연결
Ingress를 통해 들어온 트래픽을 내부 서비스(Nginx)로 전달
  
>   사용자 (HTTP 요청)
      ↓
AWS LoadBalancer (NLB)
      ↓
Service (type=LoadBalancer, Ingress Controller가 연결됨)
      ↓
Ingress (트래픽을 어디로 보낼지 결정)
      ↓
Service (type=ClusterIP)
      ↓
Pod 1 (192.168.5.42:80)
Pod 2 (192.168.5.43:80)
Pod 3 (192.168.5.44:80)
Pod 4 (192.168.5.45:80)

  
  📌 (1) NGINX Ingress Controller 설치


```bash
kubectl apply -f https://raw.githubusercontent.com/kubernetes/ingress-nginx/main/deploy/static/provider/cloud/deploy.yaml
```
  
  ![](https://velog.velcdn.com/images/luckyprice1103/post/9ca4c2a6-b7e4-4388-9968-7b2b70f235f2/image.png)
  
 
📌 (2) 기존 LoadBalancer를 Ingress와 연결
Ingress가 기존 LoadBalancer를 사용하도록 설정하려면, Ingress Controller에 NodePort 방식으로 노출하여 LoadBalancer가 Ingress 트래픽을 처리하도록 해야 합니다.

🔹 Ingress Controller를 NodePort로 변경


```bash
kubectl patch svc ingress-nginx-controller -n ingress-nginx -p '{"spec": {"type": "NodePort"}}'
```
```bash
kubectl get svc -n ingress-nginx
```
출력 예시:

![](https://velog.velcdn.com/images/luckyprice1103/post/b5127e6c-237a-43bc-a3da-96dc4f68ea25/image.png)

✔ NodePort 방식으로 노출됨
✔ 포트 32100과 32200이 자동 할당됨

  
할당됨

📌 (3) 기존 LoadBalancer가 Ingress로 트래픽 전달하도록 변경
기존 LoadBalancer에서 Ingress Controller의 NodePort로 트래픽을 전달합니다.

🔹 기존 LoadBalancer 서비스 변경
  ![](https://velog.velcdn.com/images/luckyprice1103/post/255d3880-3e02-4da3-9ec3-63e54fb75e2b/image.png)
```yaml
apiVersion: v1
kind: Service
metadata:
  name: my-web-service
  annotations:
    service.beta.kubernetes.io/aws-load-balancer-type: "nlb"
    service.beta.kubernetes.io/aws-load-balancer-scheme: "internet-facing"
spec:
  selector:
    app: my-web-app
  type: LoadBalancer  # 클라우드 환경에서는 LoadBalancer 자동 생성됨
  ports:
    - name: http
      protocol: TCP
      port: 80
      targetPort: 32100  # Ingress Controller의 HTTP NodePort
    - name: https
      protocol: TCP
      port: 443
      targetPort: 32200  # Ingress Controller의 HTTPS NodePort
  selector:
    app.kubernetes.io/name: ingress-nginx
```

✔ 이 설정을 적용하면:

기존 LoadBalancer (my-web-loadbalancer) 가 Ingress Controller의 NodePort로 트래픽을 전달
Ingress가 도메인 기반 트래픽을 서비스로 라우팅
Ingress가 LoadBalancer의 EXTERNAL-IP를 그대로 사용

```bash
kubectl apply -f my-web-loadbalancer.yaml
kubectl get svc
```
EXTERNAL-IP가 기존 LoadBalancer와 동일해야 함.
  
  
📌 (4) Ingress 리소스 생성
이제 Ingress를 설정하여 도메인 기반 트래픽을 서비스로 라우팅.

```yaml
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: my-web-ingress
  annotations:
    nginx.ingress.kubernetes.io/rewrite-target: /
spec:
  ingressClassName: nginx
  rules:
    - host: myweb.local
      http:
        paths:
          - path: /
            pathType: Prefix
            backend:
              service:
                name: my-web-service
                port:
                  number: 80
```
✔ 핵심 내용

ingressClassName: nginx → NGINX Ingress Controller 사용
host: myweb.local → 도메인 기반 트래픽 라우팅
backend.service.name: my-web-service → 트래픽을 my-web-service로 전달

```bash
kubectl apply -f ingress.yaml
kubectl get ingress
```

  ![](https://velog.velcdn.com/images/luckyprice1103/post/ad6987bf-95a3-4e47-9211-66c51c6d256e/image.png)

![](https://velog.velcdn.com/images/luckyprice1103/post/4e5c2ca7-c1dd-48d8-af4b-f9b1adb3dd3d/image.png)


- 에러. ingress-nginx-controller가 dns주소를 제대로 받아오지 못함.  
  
✅ 올바르게 설정된 경우, 아래 순서로 동작해야 함

my-web-service가 AWS NLB에서 받은 트래픽을 Ingress Controller(NodePort)로 전달
Ingress Controller가 트래픽을 받아서 적절한 내부 서비스로 라우팅
Ingress 리소스(ingress.yaml)가 my-web-service로 요청을 전달
> 사용자 (브라우저)
  ↓
AWS NLB (80, 443)
  ↓
Kubernetes NodePort (31814, 30256)
  ↓
Ingress-NGINX Controller (80, 443) ✅ 올바른 포트로 연결됨!
  ↓
Ingress 규칙에 따라 내부 서비스로 전달
  ↓
Kubernetes Service (my-web-service)
  ↓
Pod (my-web-app)

  - 해결 방법
  
  1️⃣ Ingress-NGINX Controller 배포

```bash
kubectl apply -f https://raw.githubusercontent.com/kubernetes/ingress-nginx/main/deploy/static/provider/cloud/deploy.yaml
```
  
Ingress Controller를 클러스터에 배포.

  
2️⃣ Ingress-NGINX 서비스 설정 (NLB 연동)

```yaml
apiVersion: v1
kind: Service
metadata:
  name: ingress-nginx-controller
  namespace: ingress-nginx
  annotations:
    service.beta.kubernetes.io/aws-load-balancer-type: "nlb"
    service.beta.kubernetes.io/aws-load-balancer-scheme: "internet-facing"
spec:
  type: LoadBalancer
  externalTrafficPolicy: Local
  selector:
    app.kubernetes.io/name: ingress-nginx
  ports:
    - name: http
      nodePort: 31814
      port: 80
      protocol: TCP
      targetPort: 80  # Ingress Controller 내부 포트와 일치
    - name: https
      nodePort: 30256
      port: 443
      protocol: TCP
      targetPort: 443  # Ingress Controller 내부 포트와 일치
```
> ⚠️ 중요:
targetPort: 80, 443 → Ingress Controller가 실제로 수신하는 포트
nodePort: 31814, 30256 → NodePort를 통해 NLB가 연결되는 포트
externalTrafficPolicy: Local → 클라이언트의 실제 IP를 유지하도록 설정

  
3️⃣ 애플리케이션 서비스 (my-web-service)

```yaml
apiVersion: v1
kind: Service
metadata:
  name: my-web-service
  namespace: default
spec:
  selector:
    app: my-web-app
  type: ClusterIP
  ports:
    - protocol: TCP
      port: 80
      targetPort: 80  # 애플리케이션 Pod 내부에서 사용하는 포트
```

4️⃣ Ingress 설정
```yaml
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: nginx-ingress
  namespace: default
  annotations:
    nginx.ingress.kubernetes.io/rewrite-target: /
spec:
  ingressClassName: nginx
  rules:
    - http:
        paths:
          - path: /
            pathType: Prefix
            backend:
              service:
                name: my-web-service  # 내부 서비스
                port:
                  number: 80
```

host: myweb.local 또는 NLB의 DNS 주소 사용 가능
nginx.ingress.kubernetes.io/rewrite-target: / → 요청 URL을 재작성하여 백엔드 서비스에 전달
service.name: my-web-service → 트래픽이 전달될 서비스
적용 명령어

  
  접속 성공..
![](https://velog.velcdn.com/images/luckyprice1103/post/c25b5113-a40b-4714-a843-3d8a69d3771b/image.png)
  
  
애플리케이션을 여러 개의 파드로 배포하고, 외부에서 접근할 수 있도록 서비스(Service)를 설정하여 정상적으로 동작할 수 있음.

![](https://velog.velcdn.com/images/luckyprice1103/post/5b1a6e0b-8483-401b-8909-78405bcde3f3/image.png)

 
### 5. 결과
  ✅ 1단계
✔ 쿠버네티스 멀티노드 클러스터 구축 완료
✔ 웹 애플리케이션 (Nginx 기반) 배포 완료
✔ 서비스(Service) 및 Ingress 설정 완료
✔ AWS LoadBalancer(NLB) 연결 완료
✔ 외부에서 웹 애플리케이션 정상 접속 확인