![](https://velog.velcdn.com/images/luckyprice1103/post/aa9b9763-2998-4083-ac7c-0c8a5aa63662/image.png)

## 1. 쿠버네티스 설치

- 쿠버네티스-기초

https://drive.google.com/file/d/1oBD9E4zF4RzN1EQKVx-ZGDrwy-1fIIcB/view?usp=sharing

- minikube 환경 셋팅 (EC2 Instance Ubuntu 22.04LTS, AMD)

### 1. docker 설치

``` bash
(https://docs.docker.com/engine/install/ubuntu/)

Add Docker's official GPG key:

sudo apt-get update
sudo apt-get install ca-certificates curl
sudo install -m 0755 -d /etc/apt/keyrings
sudo curl -fsSL https://download.docker.com/linux/ubuntu/gpg -o /etc/apt/keyrings/docker.asc
sudo chmod a+r /etc/apt/keyrings/docker.asc

Add the repository to Apt sources:

echo \
"deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/docker.asc] https://download.docker.com/linux/ubuntu \
$(. /etc/os-release && echo "${UBUNTU_CODENAME:-$VERSION_CODENAME}") stable" | \
sudo tee /etc/apt/sources.list.d/docker.list > /dev/null
sudo apt-get update

sudo apt-get install docker-ce docker-ce-cli [containerd.io](http://containerd.io/) docker-buildx-plugin docker-compose-plugin

sudo usermod -aG docker $USER
newgrp docker
```

### 2. minikube 설치

``` bash
 (https://minikube.sigs.k8s.io/docs/start/?arch=%2Flinux%2Fx86-64%2Fstable%2Fbinary+download)

curl -LO https://github.com/kubernetes/minikube/releases/latest/download/minikube-linux-amd64

sudo install minikube-linux-amd64 /usr/local/bin/minikube && rm minikube-linux-amd64

minikube start

alias kubectl="minikube kubectl --"

kubectl
```


## 2. 포드 생성.

### 포드생성 1
``` bash
kubectl run myfirstnginx --image nginx
```

![](https://velog.velcdn.com/images/luckyprice1103/post/ea24b223-f09d-4ec2-8135-8dc9599081ca/image.png)

``` bash
kubectl delete pod myfirstnginx
```

![](https://velog.velcdn.com/images/luckyprice1103/post/31a3982e-4828-4fd7-94e7-a6d8ca78673f/image.png)

### 포드생성 2 - manifest를 이용한 포드 생성.

```bash
apiVersion: v1
kind: Pod
metadata:
  labels:
    run: mynginx
  name: mynginx
spec:
  containers:
  - image: nginx
    name: mynginx

```

apiVersion: v1 → Kubernetes API 버전 (Pod는 v1에서 지원됨)
kind: Pod → 생성하려는 Kubernetes 리소스의 종류 (Pod)
metadata
name: mynginx → Pod의 이름
labels → Pod에 라벨을 추가 (라벨은 선택 사항)
spec
containers → Pod에 포함될 컨테이너 목록
image: nginx → 사용할 컨테이너 이미지 (nginx)
name: mynginx → 컨테이너의 이름

![](https://velog.velcdn.com/images/luckyprice1103/post/f1f520ed-fb2d-424e-ace1-148a8116d1b7/image.png)
![](https://velog.velcdn.com/images/luckyprice1103/post/c7d2d5a1-3e35-476c-b1b3-a43808ce7064/image.png)![](https://velog.velcdn.com/images/luckyprice1103/post/5f6fc398-606b-467a-ae16-27dffdf31262/image.png)

### 포드생성 3 - manifest를 자동 생성.

``` bash
kubectl run ournginx --image nginx --dry-run=client -o yaml > ournginx.yaml
```

kubectl run ournginx → ournginx라는 Pod 실행
--image=nginx → nginx 컨테이너 이미지를 사용
--dry-run=client → 실제로 Pod를 생성하지 않고, YAML만 출력
-o yaml → 출력을 YAML 형식으로 변환
ournginx.yaml → 출력을 ournginx.yaml 파일로 저장
생성된 파일.

![](https://velog.velcdn.com/images/luckyprice1103/post/d2c644fc-559d-4aaa-b435-eb2463dc9658/image.png)

``` bash
kubectl apply -f ournginx.yaml
```

### 포드 관리 - 실행중인 포드 인스턴스의 로그 확인

``` bash
kubectl logs -f mynginx
```

## 3. k8s hello-world

``` bash
kubectl run hello-world --image=hello-world --restart=Never
```

![](https://velog.velcdn.com/images/luckyprice1103/post/24dfb39f-203f-43fc-8153-c4b51a0d0ddb/image.png)


![](https://velog.velcdn.com/images/luckyprice1103/post/1c4c142e-a539-48d9-9f2c-8f2554549900/image.png)![](https://velog.velcdn.com/images/luckyprice1103/post/4ea0477e-f011-4a2c-a656-130330dfe792/image.png)

--image hello-world를 사용했는데, 이 이미지는 단순히 "Hello, World!"를 출력하고 종료하는 컨테이너.
쿠버네티스에서 컨테이너가 실행이 끝나면 파드는 종료 상태(Completed)가 됨.
하지만 Deployment는 지속적으로 실행되는 애플리케이션을 기대하기 때문에, 컨테이너가 종료되면 다시 실행하려고 함.
그래서 CrashLoopBackOff (크래시 루프 백오프) 상태에 빠지게 됨.


## 4. k8s webserver deployment

``` bash
kubectl create deployment webserver --image=nginx
deployment.apps/webserver created
kubectl get deploy,po
kubectl scale deployment webserver --replicas=5

```

webserver라는 Deployment의 파드(Pod) 개수를 5개로 늘림.
![](https://velog.velcdn.com/images/luckyprice1103/post/42227aee-d9fd-4ed2-bb45-2e1bc154f4c4/image.png)


## 5. busybox

```bash
kubectl run busybox --image=busybox --restart=Never --rm -it -- sh

```
![](https://velog.velcdn.com/images/luckyprice1103/post/4e018e2b-5119-47c7-b853-548a735b854e/image.png)


![](https://velog.velcdn.com/images/luckyprice1103/post/f9e9d916-7e34-4f30-b18a-5ace6fdaba45/image.png)


## 6. 프로브


### 🔹 1. 활성 프로브 (Liveness Probe)
활성 프로브는 컨테이너가 정상적으로 실행 중인지 체크하는 기능

✅ 역할
컨테이너 내부 애플리케이션이 정상적으로 실행되고 있는지 주기적으로 검사.
만약 활성 프로브 검사에 실패하면, 쿠버네티스는 해당 컨테이너를 강제 종료하고 다시 시작(재시작, Restart) 함.
프로브를 사용하려면 매니페스트에 명시적으로 설정해야 함.
✅ 사용 예시 (활성 프로브)

```yaml
livenessProbe:
  httpGet:
    path: /health
    port: 8080
  initialDelaySeconds: 5
  periodSeconds: 10
```
http://<pod-ip>:8080/health에 주기적으로 요청을 보냄.
만약 응답이 없거나 500 오류가 3번 발생하면 → 파드를 강제로 종료하고 재시작.
📌 즉, 활성 프로브는 "컨테이너가 살아 있는지" 확인하는 기능!
➡ 컨테이너가 죽었거나 응답하지 않으면 다시 시작해야 하는 경우 사용.

### 🔹 2. 준비 상태 프로브 (Readiness Probe)
준비 상태 프로브는 컨테이너가 외부 요청을 받을 준비가 되었는지 확인하는 기능이야.
  
✅ 역할
컨테이너가 완전히 초기화되었고, 실제로 요청을 처리할 수 있는 상태인지 체크.
만약 준비 상태 프로브 검사에 실패하면, 해당 파드는 서비스(LoadBalancer, ClusterIP)에서 트래픽을 받지 않도록 설정됨.
즉, 트래픽이 아직 준비되지 않은 파드로 전달되지 않도록 보호.
✅ 사용 예시 (준비 상태 프로브)

``` yaml
readinessProbe:
  httpGet:
    path: /ready
    port: 8080
  initialDelaySeconds: 5
  periodSeconds: 10
```
  
http://<pod-ip>:8080/ready에 주기적으로 요청.
만약 준비되지 않았다고 응답하면 트래픽을 받지 않도록 제외됨.
📌 즉, 준비 상태 프로브는 "컨테이너가 정상적으로 요청을 받을 수 있는 상태인지" 확인하는 기능!
➡ 애플리케이션이 초기화되거나 DB 연결이 필요할 때 유용.

  ![](https://velog.velcdn.com/images/luckyprice1103/post/8c4bb69b-9dcd-4690-a37c-50b6d964c907/image.png)

  
  ✅ 왼쪽: 기존 로드밸런서의 헬스 체크
기존 로드밸런서는 주기적으로 웹 서버에 GET 요청을 보냄.
만약 웹 서버 #2가 500 에러를 5번 이상 응답하면, 로드밸런서는 웹 서버 #2로 트래픽 전송을 중지.
하지만 서버 자체를 재시작하지는 않음!
(즉, 웹 서버 #2가 다운된 상태라도 자동 복구되지 않음.)
  
✅ 오른쪽: 쿠버네티스의 헬스 체크
kubelet이 각 파드의 상태를 주기적으로 확인.
만약 파드 #2가 500 에러를 3번 이상 반환하면, kubelet이 파드를 재시작.
즉, 쿠버네티스는 트래픽을 차단하는 것뿐만 아니라, 자체적으로 파드를 복구함.
📌 기존 로드밸런서는 단순히 트래픽을 차단하지만, 쿠버네티스는 아예 파드를 재시작하여 복구 가능!
➡ 즉, 쿠버네티스의 헬스 체크는 더 강력한 자기 복구 기능을 제공.

  
  
## 7. health check 실습.
  
  
✅ 1. hc-probe/webapi-pod.yml (Kubernetes Pod 설정 파일)
📌 이 파일은 쿠버네티스에서 실행할 Pod을 정의한 매니페스트.
```yaml
apiVersion: v1
kind: Pod
metadata:
  name: webapl
spec:
  containers:
  - name: webapl
    image: maho/webapl:0.1
    livenessProbe:
      httpGet:
        path: /healthz
        port: 3000
      initialDelaySeconds: 3
      periodSeconds: 5
    readinessProbe:
      httpGet:
        path: /ready
        port: 3000
      initialDelaySeconds: 15
      periodSeconds: 6

```
  
- livenessProbe → /healthz 경로를 5초마다 호출하여 컨테이너가 정상인지 확인.
만약 500 오류가 발생하면 컨테이너를 재시작.
- readinessProbe → /ready 경로를 6초마다 호출하여 컨테이너가 서비스 요청을 받을 준비가 되었는지 확인.
준비되지 않으면 서비스에서 해당 파드를 제외하여 트래픽을 전달하지 않음.  

✅ 2. hc-probe/webapl/Dockerfile (Docker 컨테이너 생성 파일)
📌 이 파일은 컨테이너 이미지를 빌드하는 Dockerfile.
  
``` yaml
FROM alpine:latest
## Node.js  https://pkgs.alpinelinux.org/package/edge/main/x86_64/nodejs
RUN apk update && apk add --no-cache nodejs npm
## 의존 모듈
WORKDIR /
ADD ./package.json /
RUN npm install
ADD ./webapl.js /
## 애플리케이션 기동
CMD node /webapl.js
```
✅ 3. hc-probe/webapl/package.json (Node.js 애플리케이션 패키지 정보)
 📌 Node.js 프로젝트의 의존성을 관리하는 파일
``` yaml
  {
  "name": "webapl",
  "version": "1.0.0",
  "description": "",
  "main": "webapl.js",
  "scripts": {
    "test": "echo \"Error: no test specified\" && exit 1"
  },
  "author": "",
  "license": "ISC",
  "dependencies": {
    "express": "^4.16.3"
  }
}

```
  
✅ 4. hc-probe/webapl/webapl.js (Node.js 웹 애플리케이션)
📌 이 파일은 실제로 실행될 Node.js 웹 애플리케이션.
✔ Express.js 기반의 간단한 웹 서버로, /healthz와 /ready 엔드포인트를 제공.
  
``` bash
// 모의 애플리케이션
//
const express = require('express')
const app = express()
var start = Date.now()
// Liveness 프로브 핸들러
// 기동 후 40초가 되면, 500 에러를 반환한다.
// 그 전까지는 HTTP 200 OK를 반환한다.
// 즉, 40초가 되면, Liveness프로브가 실패하여 컨테이너가 재기동한다.
//
app.get('/healthz', function(request, response) {
    var msec = Date.now() - start
    var code = 200
    if (msec > 40000 ) {
    code = 500
    }
    console.log('GET /healthz ' + code)
    response.status(code).send('OK')
})
// Rediness 프로브 핸들러
// 애플리케이션의 초기화 시간으로
// 기동 후 20초 지나고 나서부터 HTTP 200을 반환한다.
// 그 전까지는 HTTPS 200 OK를 반환한다.
app.get('/ready', function(request, response) {
    var msec = Date.now() - start
    var code = 500
    if (msec > 20000 ) {
    code = 200
    }
    console.log('GET /ready ' + code)
    response.status(code).send('OK')
})
// 첫 화면
//
app.get('/', function(request, response) {
    console.log('GET /')
    response.send('Hello from Node.js')
})
// 서버 포트 번호
//
app.listen(3000);
```
  
  
🔥 전체 흐름 정리
1️⃣ 컨테이너가 실행됨
2️⃣ 처음 20초 동안 ReadinessProbe가 실패 → 서비스에서 제외됨 (트래픽 차단)
3️⃣ 20초 후 Readiness Probe 성공 → 트래픽 받기 시작
4️⃣ 40초 후 Liveness Probe 실패 → 컨테이너가 강제 재시작됨
5️⃣ 다시 처음부터 시작 (20초 동안 준비, 40초 후 재시작 반복)
  
  
  
```
docker build --tag evan/webapl:0.1 .
  
```  
![](https://velog.velcdn.com/images/luckyprice1103/post/22b025c5-c396-4445-949b-786de2860e0a/image.png)
  

```
 docker tag evan/webapl:0.1 luckyprice1103/webapl:0.1
 docker login
 docker push luckyprice1103/webapl:0.1
```
  ![](https://velog.velcdn.com/images/luckyprice1103/post/d4c44ab6-a0f0-4672-8ce3-eba5f85e2308/image.png)![](https://velog.velcdn.com/images/luckyprice1103/post/258bc83a-67dd-4858-b802-f1bd364d3f8f/image.png)

``` bash
kubectl apply -f webapi-pod.yml
```
![](https://velog.velcdn.com/images/luckyprice1103/post/34ed1200-dc9c-4ed6-8b14-cb9ed55c2a2d/image.png)![](https://velog.velcdn.com/images/luckyprice1103/post/60d9fb73-15f9-4467-847c-a476232a0ada/image.png)
  
✅ 결론
✔ 쿠버네티스에서 Liveness Probe와 Readiness Probe가 어떻게 동작하는지 테스트하는 코드
✔ Liveness Probe (/healthz) → 컨테이너가 죽으면 자동 재시작
✔ Readiness Probe (/ready) → 준비될 때까지 트래픽 차단
✔ 이 코드를 실행하면 40초마다 컨테이너가 재시작되는 걸 볼 수 있음


![](https://velog.velcdn.com/images/luckyprice1103/post/3c687172-d7da-45c9-a705-4040d0d264d6/image.png)



## 8. 사이드카 패턴 개념
- 하나의 파드(Pod) 안에 여러 개의 컨테이너를 함께 실행하는 패턴
일반적으로 쿠버네티스에서 하나의 파드는 하나의 애플리케이션을 실행하는 컨테이너를 포함하지만, 사이드카 패턴을 사용하면 보조적인 기능을 수행하는 컨테이너를 추가할 수 있음.

- 웹 서버 컨테이너와 최신 콘텐츠를 동기화하는 컨테이너 조합
메인 컨테이너(예: 웹 서버)와 보조 컨테이너(예: 콘텐츠 다운로드)가 함께 동작하여 기능을 확장하는 방식.

- 애플리케이션 변경 없이 사이드카 컨테이너를 추가, 교체하기 쉬운 구조
메인 애플리케이션을 수정하지 않고도, 필요한 기능을 보조 컨테이너로 추가할 수 있음.
예를 들어, 로그 수집, 인증 처리, 데이터 싱크 등 다양한 역할 수행 가능.

- 메인 컨테이너와 사이드카 컨테이너가 동일한 노드에서 실행됨
파드 내부에서 실행되므로 서로 같은 네트워크와 볼륨을 공유할 수 있음.
리소스를 효율적으로 관리할 수 있도록 최적화 가능.

- 사이드카 컨테이너는 메인 컨테이너보다 나중에 시작/종료
사이드카 컨테이너는 메인 애플리케이션을 보조하는 역할이므로, 메인 컨테이너가 먼저 실행된 후 가동되도록 설정해야 함.
반대로 종료할 때는 메인 컨테이너보다 늦게 종료되어야 안정적인 관리가 가능함.

## 9. 사이드카 패턴 실습.

``` yaml
apiVersion: v1
kind: Pod
metadata:
  name: nginx-busybox-pod
spec:
  containers:
  # 1. Nginx 웹 서버 컨테이너
  - name: nginx
    image: nginx:latest
    volumeMounts:
    - mountPath: /var/log/nginx
      name: log-volume

  # 2. 트래픽 생성 컨테이너 (Busybox)
  - name: busybox
    image: busybox:latest
    command:
    - "/bin/sh"
    - "-c"
    - |
      while true; do
        echo "Sending request to Nginx..."
        wget -qO- http://localhost:80
        sleep 10
      done
    volumeMounts:
    - mountPath: /var/log/nginx
      name: log-volume

  # 3. 로그 모니터링 컨테이너
  - name: log-checker
    image: busybox:latest
    command:
    - "/bin/sh"
    - "-c"
    - "tail -F /var/log/nginx/access.log"
    volumeMounts:
    - mountPath: /var/log/nginx
      name: log-volume

  # 모든 컨테이너가 공유하는 emptyDir 볼륨
  volumes:
  - name: log-volume
    emptyDir: {}
```

### 1. Pod 개요
이 Pod에는 3개의 컨테이너가 포함되어 있으며, 각각 역할이 다름.

- nginx (웹 서버 컨테이너):
Nginx를 실행하며, 요청을 받아 응답을 반환.
/var/log/nginx 디렉터리를 log-volume에 마운트하여 로그를 저장.

- busybox (트래픽 생성 컨테이너):
wget을 사용해 localhost:80(nginx)로 HTTP 요청을 보냄.
10초마다 반복적으로 요청을 보냄으로써 nginx의 로그가 생성되도록 유도.

- log-checker (로그 모니터링 컨테이너):
tail -f 명령어를 실행하여 /var/log/nginx/access.log를 지속적으로 출력.
log-volume을 공유하므로 nginx가 남긴 로그를 실시간으로 볼 수 있음.
### 2. emptyDir: {} 볼륨 사용
log-volume은 emptyDir로 선언됨.
emptyDir은 Pod이 살아있는 동안 유지되는 임시 볼륨으로, 모든 컨테이너가 공유 가능.
nginx에서 로그를 기록하면 log-checker 컨테이너가 이를 읽고 출력.


``` yaml
kubectl apply -f nginx-sidecar.yml
kubectl logs -f nginx-busybox-pod -c log-checker
```

![](https://velog.velcdn.com/images/luckyprice1103/post/4a110c75-446d-4139-9419-2b5f04201192/image.png)


- log-checker 컨테이너는 Nginx의 로그를 모니터링하는 역할
Nginx(메인 컨테이너)의 /var/log/nginx/access.log를 공유 볼륨을 통해 읽어 로그를 출력.
로그 분석 도구(Splunk, Fluentd) 같은 기능을 수행할 수 있음.
→ ✅ 사이드카 패턴


- busybox 컨테이너는 트래픽을 발생시키는 역할
내부적으로 wget을 사용해 Nginx에 요청을 보내서 서버가 동작하는지 확인.
다만, 이 컨테이너는 일반적인 사이드카(보조 기능)라기보다는 단순한 트래픽 생성 도구.
→ ❌ 사이드카가 아닌 테스트용 컨테이너
